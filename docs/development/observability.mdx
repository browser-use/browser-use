---
title: "Observability"
description: "Trace Browser Use's agent execution steps and browser sessions"
icon: "eye"
---

## Overview

Browser Use has native integrations with [Lucidic AI](https://lucidic.ai) and [Laminar](https://lmnr.ai) - powerful platforms for tracing, monitoring, and analyzing AI agent executions. These integrations provide comprehensive visibility into browser automation workflows, agent decision-making, and performance metrics.

## Lucidic AI

<Note>
    Lucidic AI excels at step-level granularity with goal tracking, state management, and visual documentation.
</Note>

### Setup

To setup Lucidic AI, you need to install the `lucidicai` package and obtain your API key and agent ID from the [Lucidic AI platform](https://lucidic.ai).

```bash
pip install 'lucidicai>=1.2.15'
export LUCIDIC_API_KEY=<your-api-key>
export LUCIDIC_AGENT_ID=<your-agent-id>
```

You can leave these in your .env file, or pass them in during initialization.

### Usage

Initialize Lucidic AI at the start of your project and it will automatically trace all Browser Use agent steps, including goals, actions, state, and screenshots.

```python {5-9,16-19,23-25}
from langchain_openai import ChatOpenAI
from browser_use import Agent
import asyncio

import lucidicai as lai

# Initialize Lucidic AI session
lai.init("Browser Automation Session")

async def main():
    agent = Agent(
        task="open google, search for AI observability tools",
        llm=ChatOpenAI(model="gpt-4o-mini"),
    )
    
    # Attach Lucidic handler to track LLM interactions
    handler = lai.LucidicLangchainHandler()
    handler.attach_to_llms(agent)
    
    result = await agent.run()
    print(result)
    
    # End the session
    lai.end_session()

asyncio.run(main())
```

### Viewing Traces

The Lucidic AI metrics overview provides a high-level dashboard for each browser automation session. 
At the top, you'll see the task description clearly displayed, followed by **key performance metrics** including **session evaluation** score (shown with a success indicator), **total cost**, execution time, total steps completed, repeated steps count, and average steps per node. 

Below these metrics, you'll find detailed success and evaluation descriptions that **explain the agent's performance**, including whether the task was completed successfully and any areas for improvement. 
The interface also features an **evaluation rubric results** section and a **prompt editor** panel that displays the action space, additional context, guardrails, planner prompt, and response formatting rules used during the session.

<img className="block" src="/images/lucidic_metrics_overview_goal_tracking.png" alt="Lucidic AI Metrics and Goal Tracking" />

The step tracking interface provides granular visibility into each action taken during browser automation. 
Each step is displayed as a card showing the **state summary** (e.g., "Planning restaurant search steps" or "Searching Google for restaurants"), with a **goal summary** describing the intended outcome. 

Steps are visually connected with dotted lines showing the flow of execution, and related steps are grouped together. 
The interface includes a trajectory progress bar showing your agent's steps. Each step card contains expandable sections for **Events** (showing LLM calls) and **Action Summary** (detailing what the agent did). 
The bottom panel provides comprehensive step details including basic information (start time, duration, cost), evaluation metrics with step scores, state overview showing the goal-action-state relationship, and a **full browser screenshot** captured at that moment in the automation flow.

<img className="block" src="/images/lucidic_step_tracking.png" alt="Lucidic AI Step Tracking Interface" />

## Laminar

<Note>
  Laminar excels at tracing browser agents by providing unified visibility into
  both browser session recordings and agent execution steps.
</Note>

### Setup

To setup Laminar, you need to install the `lmnr` package and set the `LMNR_PROJECT_API_KEY` environment variable.

To get your project API key, you can either:

- Register on [Laminar Cloud](https://lmnr.ai) and get the key from your project settings
- Or spin up a local Laminar instance and get the key from the settings page

```bash
pip install 'lmnr[all]'
export LMNR_PROJECT_API_KEY=<your-project-api-key>
```

### Usage

Then, you simply initialize the Laminar at the top of your project and both Browser Use and session recordings will be automatically traced.

```python {5-8}
from browser_use.llm import ChatOpenAI
from browser_use import Agent
import asyncio

from lmnr import Laminar
# this line auto-instruments Browser Use and any browser you use (local or remote)
Laminar.initialize(project_api_key="...") # you can also pass project api key here

async def main():
    agent = Agent(
        task="open google, search Laminar AI",
        llm=ChatOpenAI(model="gpt-4o-mini"),
    )
    result = await agent.run()
    print(result)

asyncio.run(main())
```

### Viewing Traces

You can view traces in the Laminar UI by going to the traces tab in your project.
When you select a trace, you can see both the browser session recording and the agent execution steps.

Timeline of the browser session is synced with the agent execution steps, timeline highlights indicate the agent's current step synced with the browser session.
In the trace view, you can also see the agent's current step, the tool it's using, and the tool's input and output. Tools are highlighted in the timeline with a yellow color.

<img className="block" src="/images/laminar.png" alt="Laminar" />

To learn more about these platforms:
- [Lucidic AI Documentation](https://docs.lucidic.ai)
- [Laminar Documentation](https://docs.lmnr.ai)
